1.A 从数据中学习

可学习函数$Y_p = F(Z^p, W)$，$Z^p$是第$p$个模式输入，$W$是权重矩阵。

损失函数$E^p = \mathcal{D}(D^p, F(W,Z^p))$，$D^p$表示$Z^p$的正确标签。平均损失函数$E_{train}(W)$是训练集的误差的平均数$\frac{1}{P}((Z^1-D^1)+...+(Z^P+D^P))$。学习目标是令$E_{train}$最小的$W$。

$E_{test}$和$E_{train}$之间的差距随着P增加而呈现
$$E_{test}-E_{train} = k(h/P)^\alpha$$
$h$是有效参数的规模。$P$增加后这个差距会减小。

最小化$E_{train}$称为结构风险最小化，通过最小化$E_{train}+\beta H(W)$来实现。$H(W)$称为正则化项，用于抑制过大的参数。最小化$H(W)$限制了参数空间子集的容量 。

1.B 基于梯度学习

梯度下降算法：
$$W_k = W_{k-1} - \epsilon \frac{\partial E(W)}{\partial W} $$
学习率$\epsilon$是一个常数或者变量。（别的花里胡哨的都效果不好）

随机梯度下降：权重矩阵围绕平均轨迹波动，但比常规梯度下降更快。

1.C 梯度反向传播

损失函数中存在局部最小值不是基于梯度学习的阻碍（但作者不知道是为什么）。最早产生于控制理论。

1.D 手写识别系统

困难不仅在于识别单个字符，还在于分割单词和句子。

两种解决方案：
+ 将整个单词或句子作为整体进行训练，最小化总体的损失函数。
+ 图像分割。

1.E 全局训练

将多个模块合在一起训练整个系统以最小化全局误差。

假设每个模块实现一个函数$X_n = F_n (W_n, X_{n-1})$，函数连续且可微，则
$$\begin{aligned} \frac{\partial E^p}{\partial W_n} &= \frac{\partial E^p}{\partial X_n} \frac{\partial X_n}{\partial W_n} \\ &= \frac{\partial F}{\partial W_n}(W_n,X_{n-1}) \frac{\partial E^p}{\partial X_n} \end{aligned}$$
其中$\frac{\partial F}{\partial W_n}(W_n,X_{n-1})$是在$(W_n,X_{n-1})$处$F$关于$W$的雅可比矩阵。

## 二. 识别单个字符的神经网络

传统模式识别需要手工设计特征提取器。

全连接结构会忽略输入的拓扑结构，图像在二维结构上具有强烈的局部相关性。并且全连接参数量巨大。

2.A 卷积网络

通过三个结构来确保位移，尺度和扭曲的不变性：
- 局部感受野
- 共享权重
- 空间子采样：降低特征图的分辨率，减少输出对扭曲的敏感性。

2.B LeNet-5

2.C 损失函数

均方误差损失函数：

