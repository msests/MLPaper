## 1 介绍

神经网络可以应用于语言建模，释义检测和单词嵌入。

本文提出新的神经网络架构叫做RNN Encoder-Decoder，其中编码器将变长序列转化为一个定长向量，解码器再将这个定长向量转换为另一个变长序列。

文章用这个架构
+ 训练短语转换，
+ 并对短语表中的每个短语对就行评分。

## 2 编码器-解码器架构

### 2.1 RNN网络

$$h_t = f(h_{t-1},x_t)$$
复杂点的结构有LSTM。

RNN用于学习给定序列时预测下一个符号的条件分布，即$p(x_t|x_{t-1},...,x_1)$。因此一个序列出现的概率是
$$p(X) = \prod_{t=1}^T p(x_t|x_{t-1},...,x_1)$$
### 2.2 编码器-解码器

编码器将变长序列转化为一个定长向量，解码器再将这个定长向量转换为另一个变长序列。这个目标可以表示为：
$$p(y_1,...,y_{T'}|x_1,...,x_{T})$$

编码器每次读取一个符号，当序列中所有符号读取完毕后，最后一次的隐状态将是该序列的上下文向量$c$。

解码器也是一个RNN，但在产生隐状态和输出时需要c的参与：
$$h_t = f(h_{t-1},y_{t-1},c)$$
$$y_t = g(h_t,y_{t-1},c)$$

训练目标是最大化条件似然函数：
$$max_{\theta} \frac{1}{N} \sum_{n=1}^N log p_{\theta}(\mathbf{y}_n|\mathbf{x}_n)$$

如果模型是可微的，那么就能用梯度下降来找到这个点。

模型可以用于
+ 将输入序列转换为目标序列。
+ 给输入输出序列打分，分数就是$p_{\theta}(\mathbf{y}|\mathbf{x})$。

### 2.3 GRU

遗忘门reset gate：
$$r_j = \sigma([\mathbf W_r \mathbf x]_j + [\mathbf U_r \mathbf h_{t-1}]_j)$$
其中$\sigma$是sigmoid函数。

更新门update gate：
$$z_j = \sigma([\mathbf W_z \mathbf x]_j + [\mathbf U_z \mathbf h_{t-1}]_j)$$

隐藏层输出：
$$h_j^t = z_j h_j^{t-1} + (1-z_j)\tilde h_j^t$$
$$\tilde h_j^t = \phi([\mathbf W \mathbf x]_j + [\mathbf U(\mathbf r \odot \mathbf h_{t-1})_j])$$

遗忘门控制丢弃$h_{t-1}$多少信息，更新门控制保留$h_{t-1}$多少信息。需要短期依赖的隐藏层倾向于激活遗忘门，而需要长期依赖的隐藏层倾向于激活更新门。

## 3 SMT

（跳过）

## 4 实验

### 4.1.1 模型

实验中使用的是分别包含1000个隐藏单元的编码器和解码器。输入矩阵和隐状态单元是两个地址矩阵。我们使用秩为100的矩阵来学习100维的词嵌入。$\tilde h$的激活函数是双曲正切函数，解码器在RNN置上有一层500个maxout单元，每个单元池化两个输入。使用

### 4.4 单词和短语表示

使用编码器解码器结构也可以像单词一样学习短语的词嵌入向量，使得嵌入向量具有语法和句法的信息。